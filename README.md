# hma_kinesics:  Head Movements Analysis Using Kinesics

![Block diagram of the code.](/assets/images/block-diagram.png)

This repository contains the code for generating kinemes and kineme histograms described in the ICMI 2024 paper titled "Detecting Autism from Head Movements using Kinesics'.
The code reads head movements angles yaw, pitch, and roll and generates kinemes and kineme histograms. The head movements angle sequences (PYR) are generated by fitting  3D Morphable Model to face images in each frame of the input video.  This can be done by using [3DI](https://github.com/sariyanidi/3DI), [Dense Head Pose Estimation](https://github.com/1996scarlet/Dense-Head-Pose-Estimation) or [OpenFace](https://github.com/TadasBaltrusaitis/OpenFace) and this step is not included in the code here. 
The code hma_kines.py detections produces the smallest units kines by finding the peaks and valleys at three components PYR as local extrema in both time and scale space using SIFT like scale space feature extaction method. 

The code hma_letter_detection.py generates kinemes, letters or characters of head movement by classifiying kines of PYR into one of 26 classes. Each letter correspond to an elementary unit of head movement such as noding, shaking or tilting, as shown in the table below. In this table P, Y, and R denotes pitch, yaw and roll angles of head movements while P, V and N denote peak, valley and none kines detected in these components, respectively. Thus in this coding scheme, the letter 'i' correspond to a noding of first up and then down, while the leter 'u' corresponds to shaking right and the left. Another file called summary.csv contains the summary of the video file as a sequence of head movement characters. 
</picture>


|No	|P  |Y 	 |R  | Code |        |No   |P  |Y   |R  | Code |        |No   |P  |Y   |R  | Code |
|----:|---|--- |---|------   |    ----    |----:|---|--- |---|-----------|-----|----:|---|--- |---|------| 
|0	|P	|P	|P	|**a**|		|9	|V	|P	|P	|**j**|		|18	|N	|P	|P	|**s**|
|1	|P	|P	|V	|**b**|		|10	|V	|P	|V	|**k**|		|19	|N	|P	|V	|**t**|
|2	|P	|P	|N	|**c**|		|11	|V	|P	|N	|**l**|		|20	|N	|P	|N	|**u**|
|3	|P	|V	|P	|**d**|		|12	|V	|V	|P	|**m**|		|21	|N	|V	|P	|**v**|
|4	|P	|V	|V	|**e**|		|13	|V	|V	|V	|**n**|		|22	|N	|V	|V	|**w**|
|5	|P	|V	|N	|**f**|		|14	|V	|V	|N	|**o**|		|23	|N	|V	|N	|**x**|
|6	|P	|N	|P	|**g**|		|15	|V	|N	|P	|**p**|		|24	|N	|N	|P	|**y**|
|7	|P	|N	|V	|**h**|		|16	|V	|N	|V	|**q**|		|25	|N	|N	|V	|**z**|
|8	|P	|N	|N	|**i**|		|17	|V	|N	|N	|**r**|		|26	|N	|N	|N	|**-**|


The code hma_kinemes_detection.py generates higher level of kinemes as group of kinemes such as up-down noding (i) followed by a down-up noding (r) as 'ir'. 

The code hma_letter_histogram.py generates the histograms of kineme groups and and saves to histogram.csv file as final features.

### Introduction 
In this study, we introduce a method to succesfully extract  the basic head movement units such as noding, shaking or tilting from head movement angles by utilizing the Kinesics pioneered by Birdwhistell. Our approach first defines the smallest unit of head movement, called kine, based on the anatomical constraints of the neck and head. We then quantify the location, magnitude, and duration of kines within each angular component of head movement. Through defining possible combinations of identified kines, we define a higher-level construct, kineme, which corresponds to basic head motion units such as nodding and shaking. We validate the proposed framework by predicting autism spectrum disorder (ASD) diagnosis from video recordings of interacting partners. We show that the multi-scale property of the proposed framework provides a significant advantage, as collapsing behavior across temporal scales reduces performance consistently. Finally, we incorporate another fundamental behavioral modality, namely speech, and show that distinguishing between speaking- and listening-time head movements significantly improves ASD classification performance.

### Background and Development
The work was carried out during Muhittin Gokmen's sabbatical leave from MEF University, Turkey, at the Center for Autism Research (CAR) of Children's Hospital of Philadelphia (CHOP), USA from September 2023 to September 2024.

### Installation

```
git clone https://github.com/gokmenm/hma_kinesics.git
cd hma_kinesics
python3.9 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

### Usage Example
1. Prepare input file including head movements angles yaw, pitch and roll as in the example file, 'angles.csv'. The angles are given in radians and converted to degrees in the code.
2. python3.9 hma_kinesics.py --angles_path --
### Outputs
The code generates a file called all_letters.csv including detected kinemes (letters of head movements denoted by characters a to z) and the histogram file hist.csv to use as a feature in classification tasks.

### Citing
If you use this approach or the code for your publication, please cite as 
@inproceedings{gokmen2024,
  title={Detecting Autism from Head Movements using Kinesics,
  author={Muhittin Gokmen, Evangelos Sariyanidi, Lisa Yankowitz, Casey J. Zampella,
Robert T. Schultz, and Birkan Tun√ß.
  booktitle={In Proceedings of ACM International Conference
on Multimodal Interaction (ICMI 2024)},
  pages={5 pages},
  year={2024},
  organization={ACM, New York, NY, USA}
}
